{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reacher - README\n",
    "\n",
    "The code in this repository trains a deep reinforcement learning agent to solve the Unity Environment Reacher, where a double jointed arm needs to keep its' 'hand' in the target location for as long as possible. This completes Project 2 of Udacity's Deep Reinforcement Learning Nanodegree. <br>\n",
    "\n",
    "A single copy of this environment was used to train the agent. The agent trained used an actor-critic method - the DDPG algorithm as, described in Lillicrap et.al 2015. The agent learns a deterministic policy that gives continuous action values. A descriptioin of the algorithm as parameters used is in the Report in this repository.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the agent\n",
    "\n",
    "Download a local copy of this repository.\n",
    "\n",
    "### Setup the environment.\n",
    "\n",
    "To get the environment running on your local machine, follow the following steps (as in the Udacity Project Intructions).\n",
    "\n",
    "Download the environment from one of the links below.  You need only select the environment that matches your operating system:\n",
    "\n",
    "* Linux: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/one_agent/Reacher_Linux.zip)\n",
    "* Mac OSX: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/one_agent/Reacher.app.zip)\n",
    "* Windows (32-bit): [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/one_agent/Reacher_Windows_x86.zip)\n",
    "* Windows (64-bit): [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/one_agent/Reacher_Windows_x86_64.zip)\n",
    "\n",
    "Unzip and save the environment in your local repository, and change the path in `Continuous_Control.ipynb` to match your local file structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code\n",
    "\n",
    "Run all the code in `Continuous_Control.ipynb` to train the agent. Note that the code will save information in the `checkpoints` folder every 20 episodes by default (specified by the `SAVE_EVERY` parameter). Files saved are the network parameters for both the critic and actor, and the score history. Filenames contain the timestamp of when the training process started, and also the episode number at that checkpoint. When training is complete the same information is saved with the word `Final` in the filename. <br> \n",
    "\n",
    "Note that in this repository only the final checkpoint is stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
